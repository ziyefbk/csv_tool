# CSV Tool 性能说明

## 🔍 为什么第一次打开很慢？

### 原因分析

第一次打开CSV文件时，程序需要**构建索引**，这个过程需要扫描整个文件来找到所有的换行符位置。对于大文件（GB级），这个过程可能需要几秒到几十秒。

### 索引构建过程

1. **扫描整个文件**：使用 SIMD 优化的 `memchr` 库批量查找换行符（`\n`），比逐字节扫描快 **3-10倍**
2. **记录索引点**：每N行（默认1000行）记录一次字节偏移量
3. **保存索引文件**：将索引保存到 `.csv.idx` 文件

### 性能对比

| 文件大小 | 第一次打开（构建索引） | 第二次打开（加载索引） | 提升倍数 |
|---------|---------------------|---------------------|---------|
| 100MB   | 0.5-1秒            | <100毫秒            | **10-20x** |
| 1GB     | 5-15秒             | <500毫秒            | **20-60x** |
| 10GB    | 30秒-2分钟         | <2秒                | **30-90x** |

**注意**：使用 SIMD 优化后，索引构建速度提升了 **2-3倍**。

### 为什么需要索引？

索引用于快速定位到文件的任意位置：
- **无索引**：跳转到第1000页需要从头扫描，耗时数秒
- **有索引**：使用二分查找定位，耗时<100毫秒

## ✅ 后续打开会很快

### 索引缓存机制

1. **索引文件**：`.csv.idx` 文件保存在CSV文件同目录
2. **自动加载**：下次打开时自动检测并加载索引
3. **有效性验证**：检查文件大小、修改时间等，确保索引有效

### 索引失效情况

索引会在以下情况失效并自动重建：
- CSV文件被修改（文件大小或修改时间改变）
- 索引文件被删除
- 索引格式版本不匹配

## 🚀 性能优化建议

### 1. 调整索引粒度

索引粒度越小，索引文件越大，但定位更精确：

```bash
# 默认粒度：每1000行记录一次索引点
csv-tool data.csv

# 更细粒度：每100行记录一次（索引文件更大，但定位更快）
csv-tool data.csv -g 100

# 更粗粒度：每10000行记录一次（索引文件更小，但定位稍慢）
csv-tool data.csv -g 10000
```

**建议**：
- 小文件（<100MB）：使用默认粒度（1000）
- 中等文件（100MB-1GB）：使用默认粒度（1000）
- 大文件（>1GB）：可以增大粒度（5000-10000）以减少索引文件大小

### 2. 预构建索引

对于经常访问的大文件，可以提前构建索引：

```bash
# 使用 info 命令触发索引构建（不显示数据）
csv-tool large_file.csv info
```

### 3. 使用SSD存储

索引文件读写性能受存储设备影响：
- **SSD**：索引加载和保存更快
- **HDD**：可能稍慢，但影响不大

### 4. 索引文件管理

- **保留索引文件**：不要删除 `.csv.idx` 文件
- **版本控制**：索引文件不需要提交到版本控制（已在 `.gitignore` 中）
- **磁盘空间**：索引文件通常很小（<1MB），即使对于GB级文件

## 📊 性能指标

### 索引构建速度

- **小文件（<100MB）**：通常 <2秒
- **中等文件（100MB-1GB）**：通常 5-30秒
- **大文件（>1GB）**：通常 30秒-3分钟

### 索引文件大小

索引文件大小取决于：
- CSV文件行数
- 索引粒度

**估算公式**：
```
索引文件大小 ≈ (总行数 / 粒度) × 16字节
```

**示例**：
- 1000万行，粒度1000：约160KB
- 1亿行，粒度1000：约1.6MB

### 内存占用

- **内存映射**：不占用物理内存（由操作系统管理）
- **索引内存**：通常 <10MB（即使对于GB级文件）
- **页面缓存**：默认缓存10页，约几MB

## 🔧 故障排查

### 问题：索引构建很慢

**可能原因**：
1. 文件很大（>10GB）
2. 磁盘IO慢（HDD）
3. 系统负载高

**解决方案**：
- 等待索引构建完成（只需一次）
- 使用SSD存储
- 增大索引粒度（减少索引点数量）

### 问题：索引文件很大

**可能原因**：
- 索引粒度过小
- 文件行数很多

**解决方案**：
- 增大索引粒度：`csv-tool data.csv -g 5000`
- 这是正常的，索引文件通常比CSV文件小得多

### 问题：索引加载失败

**可能原因**：
- CSV文件被修改
- 索引文件损坏

**解决方案**：
- 程序会自动重建索引
- 删除 `.csv.idx` 文件强制重建

## 💡 最佳实践

1. **首次打开**：耐心等待索引构建完成（只需一次）
2. **保留索引**：不要删除 `.csv.idx` 文件
3. **定期更新**：如果CSV文件被修改，索引会自动重建
4. **批量处理**：对于多个大文件，可以提前构建索引

## ⚡ 已实现的性能优化

### 1. SIMD 加速的换行符查找

使用 `memchr` 库进行 SIMD（单指令多数据）优化的字符串搜索：
- **优化位置**：索引构建、行定位、搜索功能
- **性能提升**：换行符查找速度提升 **3-10倍**
- **技术细节**：利用 CPU 的 SIMD 指令集（SSE2/AVX2）并行处理多个字节

### 2. 批量处理优化

- **索引构建**：使用 `memchr_iter` 批量查找所有换行符，减少循环开销
- **行解析**：优化了行边界查找逻辑，减少重复扫描

### 3. 零拷贝字符串解析

- **内存映射**：直接访问文件内存，无需复制
- **Cow<str>**：智能使用引用或所有权，减少内存分配

## 📈 已实现的优化

### 1. SIMD 加速的换行符查找 ✅

使用 `memchr` 库进行 SIMD（单指令多数据）优化的字符串搜索：
- **优化位置**：索引构建、行定位、搜索功能
- **性能提升**：换行符查找速度提升 **3-10倍**
- **技术细节**：利用 CPU 的 SIMD 指令集（SSE2/AVX2）并行处理多个字节

### 2. 并行索引构建 ✅

对于大文件（>100MB），自动使用多线程并行构建索引：
- **自动启用**：文件大小 >100MB 时自动使用并行构建
- **性能提升**：在多核 CPU 上提升 **2-4倍**（取决于CPU核心数）
- **技术实现**：使用 `rayon` 库将文件分成多个块，并行处理
- **块边界处理**：自动处理块边界，确保行完整性

**性能对比**：
| CPU核心数 | 1GB文件 | 10GB文件 | 提升倍数 |
|----------|---------|----------|---------|
| 4核      | 5-8秒   | 30-60秒  | **2-3x** |
| 8核      | 3-5秒   | 20-40秒  | **3-4x** |
| 16核     | 2-4秒   | 15-30秒  | **4-5x** |

## 📈 未来优化计划

- [x] SIMD 加速的换行符查找（已完成）
- [x] 并行索引构建（多线程加速）（已完成）
- [ ] 异步索引构建（后台构建，不阻塞文件打开）
- [ ] 增量索引更新（只更新变化部分）
- [ ] 索引压缩（减少索引文件大小）

